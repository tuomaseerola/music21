{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "corpus_demo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tuomaseerola/music21/blob/master/corpus_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vv5kdOJzfLPe"
      },
      "source": [
        "#Music21 Corpus Analysis\n",
        "\n",
        "\n",
        "\n",
        "Tuomas Eerola, Durham University, UK.\n",
        "\n",
        "This is a companion to the first music21 demo in Music and Science Module. The Colab ([Google Colaboratory](http://colab.research.google.com/) idea is from Myke Cuthbert, which allows any computer to run music21 analyses without fuss in a browser window. These demos have been build around the nice examples provided in [_music21_ Documentation](http://web.mit.edu/music21/doc/index.html) and edited with Durham music students at demo sessions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4JOrFGjfLPg"
      },
      "source": [
        "# 1 Build music21 environment in Colab\n",
        "\n",
        "First we build a virtual machine that will be able run _music21_ in your browser.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KH6lywqEfLPh"
      },
      "source": [
        "## 1.1 Install Music21"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64Pcp5eHfLPj"
      },
      "source": [
        "!pip install --upgrade music21\n",
        "!add-apt-repository ppa:mscore-ubuntu/mscore-stable -y\n",
        "!apt-get update\n",
        "!apt-get install musescore"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQp8VgRufLPu"
      },
      "source": [
        "## 1.2 Modify the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHmENvV2fLPv"
      },
      "source": [
        "!apt-get install xvfb\n",
        "!sh -e /etc/init.d/x11-common start\n",
        "import os\n",
        "os.putenv('DISPLAY', ':99.0')\n",
        "!start-stop-daemon --start --pidfile /var/run/xvfb.pid --make-pidfile --background --exec /usr/bin/Xvfb -- :99 -screen 0 1024x768x24 -ac +extension GLX +render -noreset\n",
        "\n",
        "from music21 import *\n",
        "us = environment.UserSettings()\n",
        "us['musescoreDirectPNGPath'] = '/usr/bin/mscore'\n",
        "us['directoryScratch'] = '/tmp'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USrYDSb7fLP6"
      },
      "source": [
        "## 1.3 Test that everything works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmd3vjuofLP7"
      },
      "source": [
        "opus133 = corpus.parse('beethoven/opus133.mxl') # we \"parse\" one specific work from the corpus\n",
        "opus133.measures(1, 4).show() # Show first 4 bars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gu9zgODwfLQk"
      },
      "source": [
        "# 2 Corpus analysis\n",
        "In the previous demo we got to know _music21_ and extracted some interesting musical properties from single pieces of music. Now it is time to apply the analyses to a corpus, a collection of pieces."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjpFiqxIfLQl"
      },
      "source": [
        "## 2.1 Corpus and metadata\n",
        "Let's work with the build-in corpus of *Music21*. The system has neat architecture for searching, combining and loading all pieces with certain metadata. Also, it is typical that the pieces themselves contain different types of metadata."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4ZbF8o8fLQl"
      },
      "source": [
        "# What other information besides the score do we have about a piece of music?\n",
        "opus3no1 = corpus.parse('corelli/opus3no1/1grave') # Get one Corelli Sonata\n",
        "print(opus3no1.metadata.all()) # Show metadata\n",
        "\n",
        "partStream = opus3no1.parts.stream() # Show the list of instruments\n",
        "for p in partStream:\n",
        "    print(p.id)\n",
        "\n",
        "opus3no1.measures(1,4).show()        # Plot first 4 bars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O02wm5tOyeoR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtRce2tgykZX"
      },
      "source": [
        "# Let's select a corpus of all works composed by Giovanni Palestrina\n",
        "corpus1 = corpus.search(composer='palestrina')\n",
        "print(corpus1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_KCERr-yzSw"
      },
      "source": [
        "# From this corpus, let us find works that are titled 'Kyrie'\n",
        "corpus2 = corpus1.search(title='Kyrie')\n",
        "print(corpus2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OILxRxKoy3Zu"
      },
      "source": [
        "# What about even more specific, compositions that have the word \"Papae\" in it in Palestrina's Kyrie corpus?\n",
        "corpus3 = corpus2.search(parentTitle='Papae')\n",
        "print(corpus3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa_7wqCkfLQn"
      },
      "source": [
        "# is this the famous Missa Papae Marcelli?\n",
        "s=corpus.parse(corpus3[0]) \n",
        "s.measures(1,7).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1ql-Zu01tnJ"
      },
      "source": [
        "#### LEARNING TASK 1\n",
        "\n",
        "*Was this the famous Missa Papae Marcelli? Can you attempt to find other famous masses from the corpus just using the titles (Sine Nomine, Spem in Alium, Missa Brevis). * \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWSfRjiafLQp"
      },
      "source": [
        "# You could display all full titles of Palestrina's Kyries:\n",
        "for work in corpus2:\n",
        "    score = corpus.parse(work)\n",
        "    print(score.metadata.parentTitle)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EawtVr5bfLQs"
      },
      "source": [
        "## 2.2 Corpus analysis of keys\n",
        "\n",
        "Were the Bach chorales written in specific keys? Perhaps the keys with only have one or two sharps and flats were regularly utilised since they are easier to perform and notate? Are there more chorales in major mode than in minor? \n",
        "\n",
        "Let's look at the key distribution across chorales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UPDdw9yfLQs"
      },
      "source": [
        "# We first select Bach 4-part works in music21\n",
        "chorales = corpus.search(composer='J.S. Bach',numberOfParts=4)\n",
        "print(chorales)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSUXcuKafLQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "614ac2d5-9b5f-41c6-b295-9c3248d5b4ff"
      },
      "source": [
        "# Next we analyse these 319 entries and extract key from each\n",
        "from music21 import*\n",
        "import matplotlib.pyplot as plt # Load some extra plotting libraries\n",
        "\n",
        "chorales = corpus.search(composer='J.S. Bach',numberOfParts=4)\n",
        "\n",
        "dict = {}\n",
        "dict2 = {}\n",
        "counter=1; maxlen = len(chorales)\n",
        "for chorale in chorales:\n",
        "   print('Analysing', counter,'/',maxlen, chorale.metadata.title,'...')\n",
        "   score = corpus.parse(chorale)\n",
        "   key = score.analyze('key').tonicPitchNameWithCase\n",
        "   key2 = score.analyze('key').mode\n",
        "   dict[key] = dict[key] + 1 if key in dict.keys() else 1\n",
        "   dict2[key2] = dict2[key2] + 1 if key2 in dict2.keys() else 1\n",
        "   counter +=1\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysing 319 / 320 None ...\n",
            "Analysing 320 / 320 None ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lC_x5MVfLQx"
      },
      "source": [
        "# Plot the results\n",
        "ind = [i for i in range(len(dict))]\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(ind, dict.values())\n",
        "ax.set_title('Frequency of Each Key')\n",
        "ax.set_ylabel('Frequency')\n",
        "plt.xticks(ind, dict.keys(), rotation='horizontal',size=12)\n",
        "plt.show()\n",
        "print(dict2) # print the frequency of major and minor keys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcO6DooZfLQz"
      },
      "source": [
        "#### LEARNING TASK 2\n",
        "\n",
        "*How do you interpret the key data of chorales? Note that within Bach chorales, there are also some modal chorales and sometimes the definition of the key is ambiguous.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6Zcjt-ofLQ1"
      },
      "source": [
        "### Clarity of key (optional)\n",
        "In the example above, we analysed the most likely in each chorael. There are some chorales where they key is ambiguous, which can be explored by obtaining the tonalCertainty measure, which underlies the key analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kD5WOCX-fLQ1"
      },
      "source": [
        "chorales = corpus.search(composer='J.S. Bach',numberOfParts=4)\n",
        "print(chorales)\n",
        "\n",
        "c=[]\n",
        "title=[]\n",
        "counter=0; maxlen = len(chorales)\n",
        "for chorale in chorales:\n",
        "   print('Analysing', counter,'/',maxlen, chorale.metadata.title,'...')\n",
        "   score = corpus.parse(chorale)\n",
        "   tc = score.analyze('key')\n",
        "   c.append(tc.correlationCoefficient) # get the correlation to the highest key\n",
        "   title.append(score.metadata.title)\n",
        "   counter +=1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am5ls1PbfLQ3"
      },
      "source": [
        "# Let's see what the correlations look like\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(c, 'bo:',markersize=5,markerfacecolor='r')\n",
        "fig.set_size_inches(20, 10)\n",
        "ax.set_ylabel('Correlation coefficient',size=15)\n",
        "ax.set_xlabel('Nro in corpus',size=15)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9IEL9cyfLQ5"
      },
      "source": [
        "# There are few chorales where the correlations are lower than the other chorales, say under 0.85. \n",
        "# Let's look at those chorales\n",
        "\n",
        "ambiguous = [ n for n,i in enumerate(c) if i < 0.85 ] # get indices of tonally ambiguous chorales.\n",
        "print('Ambiguous keys can be found in:',ambiguous)\n",
        "\n",
        "# let's look at one of these\n",
        "score = corpus.parse(chorales[ambiguous[3]])\n",
        "tc = score.analyze('key')\n",
        "print(score.metadata.title,':',tc.correlationCoefficient)\n",
        "score.show()\n",
        "\n",
        "# This is G minor Dorian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUklZH5EfLQ6"
      },
      "source": [
        "## 2.4 Corpus analysis of vocal range\n",
        "\n",
        "**Are the basses expected to sing over a larger range than the tenors? **\n",
        "\n",
        "Has the vocal range been the same for SATB works over the centuries? Of course we do not always know what pitch was the score originally mapped onto but at least the vocal ranges should be comparable between in soprano, alto, tenor and bass voices.\n",
        "\n",
        "Let's explore the vocal ranges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1DJhXESfLQ7"
      },
      "source": [
        "import statistics\n",
        "# Start with Bach chorales\n",
        "chorales = corpus.search(composer='J.S. Bach',numberOfParts=4)\n",
        "\n",
        "soprano_range = []\n",
        "alto_range = []\n",
        "tenor_range = []\n",
        "bass_range = []\n",
        "for chorale in chorales:                                          # Loop across chorales\n",
        "    s = corpus.parse(chorale)\n",
        "    for el in s.recurse().parts:                                  # Loop across the parts\n",
        "        #print(el.offset, el, el.analyze('range').semitones)\n",
        "        #print(el.partName)\n",
        "        if 'Soprano' in el.partName:\n",
        "            soprano_range.append(el.analyze('range').semitones)   # Calculate range if the part is soprano\n",
        "        if 'Alto' in el.partName:\n",
        "            alto_range.append(el.analyze('range').semitones)\n",
        "        if 'Tenor' in el.partName:\n",
        "            tenor_range.append(el.analyze('range').semitones)\n",
        "        if 'Bass' in el.partName:\n",
        "            bass_range.append(el.analyze('range').semitones)\n",
        "# Summarise the results\n",
        "print('Soprano', round(statistics.mean(soprano_range),2))\n",
        "print('Alto', round(statistics.mean(alto_range),2))\n",
        "print('Tenor', round(statistics.mean(tenor_range),2))\n",
        "print('Bass', round(statistics.mean(bass_range),2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A59wVV6BfLQ9"
      },
      "source": [
        "#### LEARNING TASK 3\n",
        "\n",
        "*Which part had the largest range and why? Is this related to the Bach chorales or would similar results be evident in another, polyphonic vocal corpus? You could try Monteverdi (replace 'J.S. Bach' with 'Monteverdi', change the 'NumberOfParts' to 6, and also replace 'Soprano' with 'Canto' and 'Bass' with 'Basso'.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eps7XyN4fLQ9"
      },
      "source": [
        "# 3 Corpus search\n",
        "\n",
        "Sometimes the useful approach is not to summarise the entire collection of music in terms of a specific feature but to search for a musical excerpt. Let's search the corpus for a theme that we have in mind. First we will select a suitable corpus of music and then search for a theme with or without the rhythms."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Pk7bzAY6fLQ-"
      },
      "source": [
        "from music21 import *\n",
        "## Select all Bach Chorales\n",
        "chorales = corpus.search(composer='J.S. Bach')\n",
        "chorales2 = corpus.search('bwv364') # Let's get the Dorian chorale again\n",
        "bwv364=corpus.parse(chorales2[0]) # Put it into a specific variable for convenience\n",
        "bwv364.measures(0, 4).show() # Display the notation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkZHwcXgfLRB"
      },
      "source": [
        "## 3.1 Theme search (pitch only)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xsqsydSfLRB"
      },
      "source": [
        "# define a theme to search. Let's first try a simple theme (G F E) without considering the rhythm.\n",
        "searchList = [note.Note('G'), note.Note('F'), note.Note('E')] # define a search pattern G-F-E\n",
        "s = bwv364.recurse().notes                 # prepares the piece for the search\n",
        "p = search.noteNameSearch(s, searchList) # executes the search\n",
        "\n",
        "# show were the exact matches were\n",
        "for notePosition in p:\n",
        "    startingNote = s[notePosition]\n",
        "    startingMeasure = startingNote.measureNumber\n",
        "    startingBeat = startingNote.beat\n",
        "    startingPart = startingNote.getContextByClass('Part')\n",
        "    print(startingNote, startingMeasure, startingBeat, startingPart)\n",
        "# This report below shows in which voice, in which bar and which beat, does the theme occur: "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgD9pUDhfLRD"
      },
      "source": [
        "## 3.2 Theme search (pitch and rhythm)\n",
        "The search above was simple and unrealistic. Let's search for a real theme with note durations\n",
        "Let's find the theme from \"Vom Himmel hoch, da komm ich her\" (\"From Heaven Above to Earth I Come\"), which was supposedly composed by Luther in 1539. The theme has been used in Bach's Christmas oratorio, but which chorale does it come from? Here we want to preserve the rhythm as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doRwKRDmfLRD"
      },
      "source": [
        "# Define the theme \"From Heaven Above to Earth I Come\")\n",
        "theme = converter.parse(\"tinynotation: 4/4 g4_From f#_hea- e_ven f#_above d_to e_earth f#_I g_come\")\n",
        "theme.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NlrFFkRfLRG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "4552fc33-64f8-4e25-cc96-4bcc65a1760a"
      },
      "source": [
        "# Here we want to preserve the approximate rhythm, but I will make all notes equally long (crotchets).\n",
        "searchStream2 = stream.Stream([key.KeySignature(1),\n",
        "                               note.Note('G4', type='quarter'),\n",
        "                               note.Note('F#4', type='quarter'),\n",
        "                               note.Note('E4', type='quarter'),\n",
        "                               note.Note('F#4', type='quarter'),\n",
        "                               note.Note('D4', type='quarter'),\n",
        "                               note.Note('E4', type='quarter'),\n",
        "                               note.Note('F#4', type='quarter'),\n",
        "                               note.Note('G4', type='quarter')])\n",
        "\n",
        "target1=[]\n",
        "target2=[]\n",
        "import time\n",
        "t = time.time()\n",
        "for i in range(100): # loop through the first 100 chorales ...\n",
        "    tmp = chorales[i].parse()\n",
        "    s = tmp.recurse().notes\n",
        "    for unused in range(12): # loop through different transpositions (up to 12 semitones)\n",
        "        s2=searchStream2.transpose(unused)\n",
        "        entryPoints = search.noteNameRhythmicSearch(s, s2.notes)\n",
        "        len1=len(entryPoints)\n",
        "        target1.append(len1)\n",
        "    len2=sum(target1)\n",
        "    target2.append(len2)\n",
        "    #print(i,target2[i])\n",
        "    target1=[]\n",
        "elapsed = time.time() - t\n",
        "print('Done! This search took',round(elapsed,1),'seconds')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-90ca344e7cf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Here we want to preserve the approximate rhythm, but I will make all notes equally long (crotchets).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m searchStream2 = stream.Stream([key.KeySignature(1),\n\u001b[0m\u001b[1;32m      3\u001b[0m                                \u001b[0mnote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'G4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'quarter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                \u001b[0mnote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'F#4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'quarter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                \u001b[0mnote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNote\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'E4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'quarter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'KeySignature'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSXjlvCMfLRJ"
      },
      "source": [
        "# Display results\n",
        "hits=[i for i, x in enumerate(target2) if x]\n",
        "print(\"These works contain the theme:\",hits)\n",
        "\n",
        "catalog = stream.Opus()\n",
        "\n",
        "for i in range(0,len(hits)):\n",
        "    tmp=chorales[hits[i]].parse()\n",
        "    incipit = tmp.measures(0,3)\n",
        "    catalog.insert(0, incipit.implode())\n",
        "catalog.show() # Display the works that contain the theme"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEYWfyTmfLRM"
      },
      "source": [
        "## 3.3 Search for the same theme in other collections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXDpXzF1fLRM"
      },
      "source": [
        "# Has the theme from \"Vom Himmel hoch, da komm ich her\" used earlier?\n",
        "\n",
        "palestrina = corpus.search('palestrina')\n",
        "print(palestrina)\n",
        "\n",
        "# let's allow some rhythmic variations and remove the note durations from the search\n",
        "searchStream3 = stream.Stream([key.KeySignature(1),\n",
        "                               note.Note('G4'),\n",
        "                               note.Note('F#4'),\n",
        "                               note.Note('E4'),\n",
        "                               note.Note('F#4'),\n",
        "                               note.Note('D4'),\n",
        "                               note.Note('E4'),\n",
        "                               note.Note('F#4'),\n",
        "                               note.Note('G4')])\n",
        "target1=[]\n",
        "target2=[]\n",
        "import time\n",
        "t = time.time()\n",
        "for i in range(100):\n",
        "    tmp = palestrina[i].parse()\n",
        "    s = tmp.recurse().notes\n",
        "    for unused in range(12): # unison to seventh\n",
        "        s2=searchStream3.transpose(unused)\n",
        "        entryPoints = search.noteNameSearch(s, s2.notes)\n",
        "        len1=len(entryPoints)\n",
        "        target1.append(len1)\n",
        "    len2=sum(target1)\n",
        "    target2.append(len2)\n",
        "    print(i,target2[i])\n",
        "    target1=[]\n",
        "print('Done! This search took',round(elapsed,1),'seconds')\n",
        "    \n",
        "hits=[i for i, x in enumerate(target2) if x]\n",
        "print(\"These works contain the theme:\",hits)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coJUaEELfLRQ"
      },
      "source": [
        "# display one example\n",
        "print(hits)\n",
        "tmp=palestrina[hits[3]].parse()        # We are looking at the fourth example in the list above\n",
        "s = tmp.recurse().notes                 # prepares the piece for the search\n",
        "p = search.noteNameSearch(s, searchStream3) # executes the search\n",
        "target1=[]\n",
        "target2=[]\n",
        "for unused in range(12): # unison to seventh\n",
        "    s2=searchStream3.transpose(unused)\n",
        "    entryPoints = search.noteNameSearch(s, s2.notes)\n",
        "    len1=len(entryPoints)\n",
        "    target1.append(len1)\n",
        "tr=[i for i, x in enumerate(target1) if x]\n",
        "\n",
        "# show were the exact matches were\n",
        "s2=searchStream3.transpose(tr[0])\n",
        "p = search.noteNameSearch(s, s2.notes) # executes the search\n",
        "for notePosition in p:\n",
        "    startingNote = s[notePosition]\n",
        "    startingMeasure = startingNote.measureNumber\n",
        "    startingBeat = startingNote.beat\n",
        "    startingPart = startingNote.getContextByClass('Part')\n",
        "    print(startingNote, startingMeasure, startingBeat, startingPart)\n",
        "tmp.measures(10, 12).show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK4ABi7H3B_f"
      },
      "source": [
        "#### LEARNING TASK 4\n",
        "\n",
        "Can you find the resemblance to the search pattern? What is the main difference? Do you think this is a coincidence or an actual precursor of the theme? How would you try to establish a link if you wished to do so? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSakGXCffLRU"
      },
      "source": [
        "# 4 References\n",
        "\n",
        "* Cuthbert, M. S., & Ariza, C. (2010). music21: A Toolkit for Computer-Aided Musicology and Symbolic Music Data. In J. Stephen Downie and Remco C. Veltkamp (Eds.). 11th International Society for Music Information Retrieval Conference (ISMIR 2010), August 9-13, 2010, Utrecht, Netherlands. pp. 637-642. [link](http://ismir2010.ismir.net/proceedings/ismir2010-108.pdf)\n",
        "\n",
        "* Cuthbert, M. S., Ariza, C., & Friedland, L. (2011). Feature Extraction and Machine Learning on Symbolic Music using the music21 Toolkit. In 11th International Society for Music Information Retrieval Conference (ISMIR 2011) (pp. 387--392). [link](http://ismir2011.ismir.net/papers/PS3-6.pdf)\n"
      ]
    }
  ]
}